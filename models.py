import os
import torch
import torch.nn as nn
import torchvision.models
import collections
import math
# 关于pytorch实现CNN的详细剖析，详见http://developer.51cto.com/art/201708/548220.htm
# 关于深度学习中编码层的作用，详见https://zhuanlan.zhihu.com/p/27549418

oheight, owidth = 228, 304

def weights_init(m):
    # Initialize filters with Gaussian random weights
    if isinstance(m, nn.Conv2d):
        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
        m.weight.data.normal_(0, math.sqrt(2. / n))
        if m.bias is not None:
            m.bias.data.zero_()
    elif isinstance(m, nn.ConvTranspose2d): # ConvTranspose2d是卷积的反操作，某种意义上可当做反卷积
        n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels
        m.weight.data.normal_(0, math.sqrt(2. / n))
        if m.bias is not None: 
            m.bias.data.zero_()
    elif isinstance(m, nn.BatchNorm2d):
        m.weight.data.fill_(1)
        m.bias.data.zero_()

class Decoder(nn.Module):
    # Decoder is the base class for all decoders

    # Module是pytorch提供的一个基类，每次我们搭建神经网络时都要继承这个类，继承这个类会使搭建网络的过程变得异常简单
    # 详见https://blog.csdn.net/u012436149/article/details/78281553

    names = ['deconv{}'.format(i) for i in range(2,10)]

    def __init__(self):
        super(Decoder, self).__init__()
        # super是继承父类(超类)的一种方法
        # 详见https://www.cnblogs.com/HoMe-Lin/p/5745297.html

        self.layer1 = None
        self.layer2 = None
        self.layer3 = None
        self.layer4 = None

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        return x

class DeConv(Decoder):
    def __init__(self, in_channels, kernel_size):
        assert kernel_size>=2, "kernel_size out of range: {}".format(kernel_size)
        super(DeConv, self).__init__()

        def convt(in_channels):
            stride = 2
            padding = (kernel_size - 1) // 2
            output_padding = kernel_size % 2
            assert -2 - 2*padding + kernel_size + output_padding == 0, "deconv parameters incorrect"
            
            module_name = "deconv{}".format(kernel_size)
            return nn.Sequential(collections.OrderedDict([
                  (module_name, nn.ConvTranspose2d(in_channels,in_channels//2,kernel_size,
                        stride,padding,output_padding,bias=False)),
                  ('batchnorm', nn.BatchNorm2d(in_channels//2)),
                  ('relu',      nn.ReLU(inplace=True)),
                ]))

        self.layer1 = convt(in_channels)
        self.layer2 = convt(in_channels // 2)
        self.layer3 = convt(in_channels // (2 ** 2))
        self.layer4 = convt(in_channels // (2 ** 3))


def choose_decoder(decoder):
    assert decoder[:6] == 'deconv' # [:6]: 列表中的第1~6位元素    [1:]: 列表中第1位以后的所有元素(不含第1位)
    assert len(decoder)==7

    num_channels = 512
    iheight, iwidth = 10, 8
    kernel_size = int(decoder[6]) # decoder的第7个元素。和c++一样，python数组的编号也是从0开始的
    return DeConv(num_channels, kernel_size)


class ResNet(nn.Module):
    def __init__(self, layers, decoder, in_channels=3, out_channels=1, pretrained=True):

        if layers not in [18, 34, 50, 101, 152]: # 这是ResNet常用的层数
            raise RuntimeError('Only 18, 34, 50, 101, and 152 layer models are defined for ResNet. Got {}'.format(layers))
        
        super(ResNet, self).__init__()
        pretrained_model = torchvision.models.__dict__['resnet{}'.format(layers)](pretrained=pretrained)
        
        if in_channels == 3:
            self.conv1 = pretrained_model._modules['conv1']
            self.bn1 = pretrained_model._modules['bn1']
        else:
            self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)
            self.bn1 = nn.BatchNorm2d(64)
            weights_init(self.conv1)
            weights_init(self.bn1)
        
        self.relu = pretrained_model._modules['relu']
        self.maxpool = pretrained_model._modules['maxpool']
        self.layer1 = pretrained_model._modules['layer1']
        self.layer2 = pretrained_model._modules['layer2']
        self.layer3 = pretrained_model._modules['layer3']
        self.layer4 = pretrained_model._modules['layer4']

        # clear memory
        del pretrained_model

        # define number of intermediate channels
        if layers <= 34:
            num_channels = 512
        elif layers >= 50:
            num_channels = 2048

        self.conv2 = nn.Conv2d(num_channels,512,kernel_size=1,bias=False)
        self.bn2 = nn.BatchNorm2d(512)
        self.decoder = choose_decoder(decoder)

        # setting bias=true doesn't improve accuracy
        self.conv3 = nn.Conv2d(32,out_channels,kernel_size=3,stride=1,padding=1,bias=False)
        self.bilinear = nn.Upsample(size=(oheight, owidth), mode='bilinear')

        # weight init
        self.conv2.apply(weights_init)
        self.bn2.apply(weights_init)
        self.decoder.apply(weights_init)
        self.conv3.apply(weights_init)

    def forward(self, x):
        # resnet
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.conv2(x)
        x = self.bn2(x)

        # decoder
        x = self.decoder(x)
        x = self.conv3(x)
        x = self.bilinear(x)

        return x